{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 確率的勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. 勾配降下法\n",
    "\n",
    "### 誤差関数(2章の復習)\n",
    "\n",
    "訓練データ\n",
    "$$\n",
    "D  = { (x_1, d_1), ... , (x_N, d_N) }\n",
    "$$\n",
    "に対する回帰問題での誤差関数\n",
    "$$\n",
    "E(w) = \\frac{1}{2} \\sum_{n = 1}^{N} ||d_n - y(x_n; w)||^2\n",
    "$$\n",
    "\n",
    "$x_i$は入力データ, $d_i$は目標出力データ, $w$はネットワークパラメータ(重みとバイアス), $y$は出力関数\n",
    "\n",
    "他クラス分類問題での誤差関数\n",
    "$$\n",
    "E(w) = - \\sum_{n = 1}^{N} \\sum_{k = 1}^{K} d_{nk} \\log y_k (x_n; w)\n",
    "$$\n",
    "$$\n",
    "d_n = [d_{n1} ... d_{nK}]^t\n",
    "$$\n",
    "\n",
    "$y_k$はk番目のユニットの出力(ソフトマックス関数)\n",
    "\n",
    "### 学習のゴール\n",
    "\n",
    "誤差関数$E(w)$を最小にする$w = { argmin }_w E(w)$を求めること\n",
    "\n",
    "### 勾配降下法\n",
    "\n",
    "上記$w$を求める簡単な方法\n",
    "\n",
    "勾配\n",
    "$$\n",
    "\\nabla E \\equiv \\frac{\\partial E}{\\partial w} = [ \\frac{\\partial E}{\\partial w_1} ... \\frac{\\partial E}{\\partial w_M} ]^t\n",
    "$$\n",
    "\n",
    "$M$は$w$の成分数, \n",
    "\n",
    "勾配降下法は現在の$w$を負の勾配方向($-\\nabla E$)に少し動かし、これを何度も繰り返す。つまり現在の重みを$w^{(t + 1)}$, 動かした後の重みを$w^{(t)}$とすると\n",
    "\n",
    "$$\n",
    "w^{(t + 1)} = w^{(t)} - \\epsilon \\nabla E\n",
    "$$\n",
    "\n",
    "$\\epsilon$は学習係数, \n",
    "\n",
    "初期値$w^{(1)}$を適当に決めて再帰的に計算すればよい。$\\epsilon$が十分に小さければ$t$の増加に伴って$E(w^{(t)})$を減少させる。よって$t$を十分に大きくすれば極小点にいつかは到達する。ただし、$\\epsilon$が大き過ぎると$E(w)$が増加してしまうこともあるし、$\\epsilon$が小さ過ぎると極小点到達までに必要な反復回数が増加し学習にかかる時間が大きくなる。\n",
    "\n",
    "勾配降下法と同じような最小化手法としては2次微分を利用するニュートン法やその派生方法(準ニュートン法など)がある。ただ、ディープネットの学習は2次微分の計算が難しいため勾配降下法を用いている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.2 確率的勾配降下法(SGD)\n",
    "\n",
    "前節では全訓練サンプル$n = 1, ... , N$に対して計算される誤差関数$E(w)$を最小化することを考えた。\n",
    "\n",
    "$$\n",
    "E(w) = \\sum_{n = 1}^{N} E_n (w)\n",
    "$$\n",
    "\n",
    "前節の$w$の更新式では、この$E(w)$を用いる。この方法をバッチ学習と呼ぶ。\n",
    "\n",
    "これに対しサンプルの一部を使ってパラメータの更新を行う方法を確率的勾配降下法(SGD)と呼ぶ。\n",
    "\n",
    "$$\n",
    "w^{(t + 1)} = w^{(t)} - \\epsilon \\nabla E_n\n",
    "$$\n",
    "\n",
    "次の$w^{(t + 1)}$の更新の際は別のサンプル$n'$を取り出し\n",
    "\n",
    "$$\n",
    "w^{(t + 1)} = w^{(t)} - \\epsilon \\nabla E_n'\n",
    "$$\n",
    "\n",
    "### バッチ学習に対する確率的勾配降下法のメリット\n",
    "\n",
    "1. 訓練データの冗長性の影響を受けない\n",
    "2. 局所的な極小解に陥りにくい\n",
    "3. パラメータの更新が小刻みに行われるので学習の途中経過をより細かく監視できる\n",
    "4. オンライン学習が可能\n",
    "\n",
    "その他の$w^{(t + 1)}$の更新方法としてはMomentum, AdaGrad, Adam等がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 「ミニバッチ」の利用\n",
    "\n",
    "重みの更新をサンプル1つ単位ではなく、少数のサンプルの集合をひとまとめにし、その単位で重みを更新する。そのひとまとめにしたサンプル集合をミニバッチと呼ぶ。\n",
    "\n",
    "t回目の更新に用いるミニバッチを$D_t$, $N_t$を$D_t$のサンプル数とする。$D_t$の含む全サンプルに対する誤差\n",
    "$$\n",
    "E_t (w) = \\frac{1}{N_t} \\sum_{n \\in D_t} E_n (w)\n",
    "$$\n",
    "を計算し、その勾配の方向にパラメータを更新する。なお、このように$E_t (w)$を$N_t$で正規化するとミニバッチのサイズを変えた時に学習係数を調整しなくてよい。\n",
    "\n",
    "通常ミニバッチ$D_t(t = 1, 2, ...)$は学習前に作成し固定しておく。ミニバッチのサイズは大体10〜100前後。他クラス分類の問題ではミニバッチ間の重みの更新のばらつきを平準化するために、ミニバッチそれぞれに各クラスから1つ以上のサンプルを入れるのが理想。\n",
    "\n",
    "なお、ミニバッチのサイズをあまり大きくすることは確率的勾配降下法のよさを損なうことになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 汎化性能と過適合\n",
    "\n",
    "### 訓練誤差\n",
    "訓練データに対する誤差\n",
    "\n",
    "前節までは訓練誤差の最小化を考えてきた\n",
    "\n",
    "### 汎化誤差\n",
    "「まだ見ぬ」サンプル$x$に対しての推定誤差、正確にはサンプルの母集団に対する誤差の期待値\n",
    "\n",
    "本当の目的は汎化誤差を最小化すること。しかし、統計的な期待値なので訓練誤差のように計算できない。よって、訓練データとは別のサンプル集合を準備し、これに対する訓練誤差と同じ方法で計算される誤差を汎化誤差の目安とする。この目的で用意するデータをテストデータ、テストデータに関する誤差をテスト誤差と呼ぶ。\n",
    "\n",
    "### 学習曲線\n",
    "\n",
    "教科書参照。訓練誤差およびテスト誤差のエポック数に対するグラフ。訓練誤差は小さくなっているが汎化誤差(テスト誤差)が大きく乖離した状態を過適合/過剰適合/過学習と呼ぶ。学習にともなってテスト誤差が増加するようならそれ以降の学習は有害なのでその時点で学習を終了する。これを早期終了/早期打ち切りと呼ぶ。\n",
    "\n",
    "過適合を起こすことなくテスト誤差(汎化誤差)を小さくできるかがニューラルネット学習の鍵\n",
    "\n",
    "1. ネットワークの層数\n",
    "2. ユニット数\n",
    "3. 学習係数\n",
    "4. 正則化の方法\n",
    "5. 学習のためのトリック\n",
    "\n",
    "等を利用して実現する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 過適合の緩和\n",
    "\n",
    "## 3.5.1 正則化\n",
    "\n",
    "学習時に重みの自由度を制約する\n",
    "\n",
    "## 3.5.2 重みの制約\n",
    "\n",
    "### 重み減衰(w\n",
    "\n",
    "誤差関数に重みの二乗和(二乗ノルム)を加算し、これを最小化する\n",
    "\n",
    "$$\n",
    "E_t (w) = \\frac{1}{N_t} \\sum_{ n \\in D_t } E_n (w) + \\frac { \\lambda }{ 2 } || w ||^2\n",
    "$$\n",
    "\n",
    "$\\lambda$はこの正則化の強さを制御するパラメータで一般に0.01〜0.000001の範囲から選ぶ。この項の追加により学習時により小さい重みが選好されるようになる。実際勾配降下法の更新式は\n",
    "\n",
    "$$\n",
    "w^{(t + 1)} = w^{(t)} - \\epsilon ( \\frac{1}{N_t} \\sum \\nabla E_n + \\lambda w^{(t)} )\n",
    "$$\n",
    "\n",
    "$- \\epsilon \\lambda w^{(t)}$と重みは自身の大きさに比例した速さで常に減衰するように修正されている。このことからこの方法は重み減衰(weight decay)と呼ばれる。\n",
    "\n",
    "なお重み減衰は通常ネットワークの重み$w^{(l)}$だけに適用し、バイアス$b^{(l)}$には適用しない。\n",
    "\n",
    "1. バイアスは総数が少ない -> 過適合しにくい\n",
    "2. 大きな値をとる必要がある\n",
    "\n",
    "\n",
    "\n",
    "### 3.5.3 ドロップアウト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 学習のトリック\n",
    "\n",
    "### 3.6.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
